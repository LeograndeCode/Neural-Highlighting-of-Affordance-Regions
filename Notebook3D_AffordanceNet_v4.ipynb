{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOG1XsPIhcwr2ARbdB9lFW5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeograndeCode/Neural-Highlighting-of-Affordance-Regions/blob/Parte-3/Notebook3D_AffordanceNet_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KwtBWLCynwPb",
        "outputId": "0cc2f6a0-5a7f-4790-9de3-ce2640b0c76a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Neural-Highlighting-of-Affordance-Regions\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #replace with drive.mount('/content/drive/', force_remount=True) if the drive has changed since last mount in order to force the remount\n",
        "%cd /content/drive/MyDrive/Neural-Highlighting-of-Affordance-Regions/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y xvfb ffmpeg libsm6 libxext6\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html\n",
        "!pip install open3d pyvirtualdisplay"
      ],
      "metadata": {
        "id": "2_ga4ZXWtU-n",
        "outputId": "dec5615a-aa69-4f1a-b0a3-4de553f2d3f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,639 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,199 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,527 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,584 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,518 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,227 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [45.2 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,560 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,859 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,663 kB]\n",
            "Fetched 28.2 MB in 3s (10.5 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsm6 is already the newest version (2:1.2.3-1build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 51 not upgraded.\n",
            "Need to get 7,815 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 7,815 kB in 1s (6,681 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123632 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-d9cjg__a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-d9cjg__a\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=5d22375ef8a89791352c41dc29d69fe49d0735d0fc632c0bbda2c476cc0924a8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kvejaj1f/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1\n",
            "Looking in links: https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html\n",
            "Collecting kaolin==0.17.0\n",
            "  Downloading https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121/kaolin-0.17.0-cp310-cp310-linux_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipycanvas (from kaolin==0.17.0)\n",
            "  Downloading ipycanvas-0.13.3-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: ipyevents in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (2.0.2)\n",
            "Requirement already satisfied: jupyter-client<8 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (6.1.12)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (3.1.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (6.3.3)\n",
            "Collecting comm>=0.1.3 (from kaolin==0.17.0)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting usd-core (from kaolin==0.17.0)\n",
            "  Downloading usd_core-24.11-cp310-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.26.4)\n",
            "Collecting pybind11 (from kaolin==0.17.0)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (11.1.0)\n",
            "Requirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.13.1)\n",
            "Collecting pygltflib (from kaolin==0.17.0)\n",
            "  Downloading pygltflib-1.16.3.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting warp-lang (from kaolin==0.17.0)\n",
            "  Downloading warp_lang-1.5.1-py3-none-manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4 in /usr/local/lib/python3.10/dist-packages (from comm>=0.1.3->kaolin==0.17.0) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (2.8.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (1.9.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.10/dist-packages (from ipycanvas->kaolin==0.17.0) (7.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->kaolin==0.17.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (4.9.0)\n",
            "Collecting dataclasses-json>=0.0.25 (from pygltflib->kaolin==0.17.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from pygltflib->kaolin==0.17.0) (1.2.15)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.0.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kaolin==0.17.0) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask->kaolin==0.17.0) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client<8->kaolin==0.17.0) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kaolin==0.17.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kaolin==0.17.0) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client<8->kaolin==0.17.0) (1.17.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pygltflib->kaolin==0.17.0) (1.17.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (24.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (4.12.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (6.5.5)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (7.16.5)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.1.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.1.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.2.2)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading ipycanvas-0.13.3-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading usd_core-24.11-cp310-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.4/25.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading warp_lang-1.5.1-py3-none-manylinux2014_x86_64.whl (84.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pygltflib\n",
            "  Building wheel for pygltflib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygltflib: filename=pygltflib-1.16.3-py3-none-any.whl size=27408 sha256=c54159aa4c7f246d86dd45ab16a40eb2d55c4e80f10d09a6afc94925f3e4ab62\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/4a/cc/0d166b319ddda5007d0dfa6087346a30c4713b0fdaeaeff304\n",
            "Successfully built pygltflib\n",
            "Installing collected packages: warp-lang, usd-core, pybind11, mypy-extensions, marshmallow, jedi, comm, typing-inspect, dataclasses-json, pygltflib, ipycanvas, kaolin\n",
            "Successfully installed comm-0.2.2 dataclasses-json-0.6.7 ipycanvas-0.13.3 jedi-0.19.2 kaolin-0.17.0 marshmallow-3.25.1 mypy-extensions-1.0.0 pybind11-2.13.6 pygltflib-1.16.3 typing-inspect-0.9.0 usd-core-24.11 warp-lang-1.5.1\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.19.0-cp310-cp310-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.26.4)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.1.0)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (11.1.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.67.1)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting flask>=3.0.0 (from open3d)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting werkzeug>=3.0.0 (from open3d)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=3.0.0->open3d) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask>=3.0.0->open3d) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=3.0.0->open3d) (3.0.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.22.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.17.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.12.14)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Downloading open3d-0.19.0-cp310-cp310-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Downloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pyvirtualdisplay, dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, werkzeug, retrying, pyquaternion, configargparse, flask, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 configargparse-1.7 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-3.0.3 ipywidgets-8.1.5 open3d-0.19.0 pyquaternion-0.9.9 pyvirtualdisplay-3.0 retrying-1.3.4 werkzeug-3.0.6 widgetsnbextension-4.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###AffordanceNet Class"
      ],
      "metadata": {
        "id": "vFNWfwgnthjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AffordanceNet Class modified with capability of choosing only some objects, in our case household objects with hand-object affordances\n",
        "\n"
      ],
      "metadata": {
        "id": "SQpppbGPoYW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import join as opj\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import h5py\n",
        "import json\n",
        "import pickle as pkl\n",
        "\n",
        "def pc_normalize(pc):\n",
        "    centroid = np.mean(pc, axis=0)\n",
        "    pc = pc - centroid\n",
        "    m = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n",
        "    pc = pc / m\n",
        "    return pc, centroid, m\n",
        "\n",
        "\n",
        "class AffordNetDataset(Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.semantic_class = 'Mug'\n",
        "        self.label_name = 'grasp'\n",
        "        self.load_data()\n",
        "        return\n",
        "\n",
        "    def load_data(self):\n",
        "        self.all_data = []\n",
        "\n",
        "        # Open the dataset file\n",
        "        with open('full_shape_train_data.pkl', 'rb') as f:\n",
        "            data = pkl.load(f)\n",
        "\n",
        "\n",
        "        # Check if the data is a list\n",
        "        if isinstance(data, list):\n",
        "            # Filter the point clouds based on the 'semantic class' attribute\n",
        "            point_clouds = [\n",
        "                pc for pc in data\n",
        "                if pc.get('semantic class') == self.semantic_class\n",
        "            ]\n",
        "        print(f\"Number of point clouds with 'semantic class' equal to {self.semantic_class}: {len(point_clouds)}\")\n",
        "\n",
        "        self.all_data = point_clouds\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data_dict = self.all_data[index]\n",
        "\n",
        "        coordinates = np.array(data_dict['full_shape']['coordinate'])\n",
        "        label = np.array(data_dict['full_shape']['label'][self.label_name])\n",
        "\n",
        "        data, _, _ = pc_normalize(coordinates)\n",
        "\n",
        "        return data, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_data)\n"
      ],
      "metadata": {
        "id": "GKHLTK2MqnOP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "2WDvKTKYtOT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "import copy\n",
        "import json\n",
        "import kaolin as kal\n",
        "import kaolin.ops.mesh\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "from itertools import permutations, product\n",
        "from Normalization import MeshNormalizer\n",
        "from render import Renderer\n",
        "from mesh import Mesh\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import grad\n",
        "from torchvision import transforms\n",
        "from utils import device, color_mesh\n",
        "import open3d as o3d\n",
        "from pyvirtualdisplay import Display\n",
        "from pytorch3d.io import IO\n",
        "\n",
        "# Pytorch3D install\n",
        "import sys\n",
        "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{pyt_version_str}\"\n",
        "])\n",
        "!pip install iopath\n",
        "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "\n",
        "\n",
        "# Data structures and functions for rendering\n",
        "from pytorch3d.structures import Meshes, Pointclouds\n",
        "from pytorch3d.vis.plotly_vis import AxisArgs, plot_batch_individually, plot_scene\n",
        "from pytorch3d.renderer import (\n",
        "    look_at_view_transform,\n",
        "    FoVOrthographicCameras,\n",
        "    PointsRasterizationSettings,\n",
        "    PointsRenderer,\n",
        "    PulsarPointsRenderer,\n",
        "    PointsRasterizer,\n",
        "    AlphaCompositor,\n",
        "    NormWeightedCompositor\n",
        ")\n",
        "from pytorch3d.io import load_objs_as_meshes, save_ply\n",
        "\n",
        "width = 256\n",
        "depth = 4       #default is 4\n",
        "out_dim = 2\n",
        "input_dim = 3\n",
        "n_augs = 1      #default is 1\n",
        "\n",
        "class NeuralHighlighter(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralHighlighter, self).__init__()\n",
        "        input_size = 3 #Dimension of the vertex\n",
        "        output_size = 2 #Dimension of the output\n",
        "                        #for the standard highlighter task there are only 2 classes: target region and not target region.\n",
        "                        #we use the element of the output vector corresponding to the probability of belonging to the target\n",
        "                        #region as the highlight probability described in the main paper.\n",
        "        layers = []\n",
        "\n",
        "        #See Appendix B (page 13)\n",
        "        #first linear layer followed by ReLU and LayerNorm\n",
        "        layers.append(nn.Linear(input_dim, width))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.LayerNorm([width]))\n",
        "        #other [depth] linear layers followed by ReLU and LayerNorm\n",
        "        # -> changing the depth hyperparameter results in a deeper/shallower net\n",
        "        # -> total depth (in terms of modules[Linear+ReLU+LayerNorm]) = [depth] + 1\n",
        "        for i in range(depth):\n",
        "            layers.append(nn.Linear(width, width))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.LayerNorm([width]))\n",
        "        #last linear layer followed by softmax in order to output probability-like values\n",
        "        layers.append(nn.Linear(width, out_dim))\n",
        "        layers.append(nn.Softmax(dim=1))\n",
        "\n",
        "        self.mlp = nn.ModuleList(layers)\n",
        "        self.model = self.mlp\n",
        "        print(self.mlp)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.model:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "def get_clip_model(clipmodel):\n",
        "    model, preprocess = clip.load(clipmodel, device=device)\n",
        "    return model, preprocess\n",
        "\n",
        "# ================== HELPER FUNCTIONS =============================\n",
        "def save_final_results(log_dir, name, mesh, mlp, vertices, colors, render, background):\n",
        "    mlp.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = mlp(vertices)\n",
        "        max_idx = torch.argmax(probs, 1, keepdim=True)\n",
        "        # for renders\n",
        "        one_hot = torch.zeros(probs.shape).to(device)\n",
        "        one_hot = one_hot.scatter_(1, max_idx, 1)\n",
        "        sampled_mesh = mesh\n",
        "\n",
        "        highlight = torch.tensor([204, 255, 0]).to(device)\n",
        "        gray = torch.tensor([180, 180, 180]).to(device)\n",
        "        colors = torch.stack((highlight/255, gray/255)).to(device)\n",
        "        color_mesh(one_hot, sampled_mesh, colors)\n",
        "        rendered_images, _, _ = render.render_views(sampled_mesh, num_views=5,\n",
        "                                                                        show=False,\n",
        "                                                                        center_azim=0,\n",
        "                                                                        center_elev=0,\n",
        "                                                                        std=1,\n",
        "                                                                        return_views=True,\n",
        "                                                                        lighting=True,\n",
        "                                                                        background=background)\n",
        "        # for mesh\n",
        "        final_color = torch.zeros(vertices.shape[0], 3).to(device)\n",
        "        final_color = torch.where(max_idx==0, highlight, gray)\n",
        "        mesh.export(os.path.join(log_dir, f\"{name}.ply\"), extension=\"ply\", color=final_color)\n",
        "        save_renders(log_dir, 0, rendered_images, name='final_render.jpg')\n",
        "\n",
        "#TODO: fix the generation of the point cloud subsequently\n",
        "#      now the point cloud generation is possible only by executing the PC_rendering.ipynb\n",
        "\n",
        "def save_point_cloud_results(log_dir, name):\n",
        "        #now i load the highlighted mesh and transpose it back to the point cloud\n",
        "        display = Display(visible=0, size=(1400, 900))\n",
        "        display.start()\n",
        "        mesh_o3d = o3d.io.read_triangle_mesh(os.path.join(log_dir, f\"{name}.ply\"))\n",
        "\n",
        "        if not mesh_o3d.has_vertex_normals():\n",
        "          mesh_o3d.compute_vertex_normals()\n",
        "\n",
        "        point_cloud = mesh_o3d.sample_points_poisson_disk(number_of_points=2048)\n",
        "\n",
        "        width_final_render, height_final_render = 1400, 900\n",
        "        render_final_pc = o3d.visualization.rendering.OffscreenRenderer(width_final_render, height_final_render)\n",
        "        material = o3d.visualization.rendering.MaterialRecord()\n",
        "        material.shader = \"defaultUnlit\"\n",
        "        render_final_pc.scene.add_geometry(\"point_cloud\", point_cloud, material)\n",
        "\n",
        "        zoom_out_factor = 0.5\n",
        "        bounding_box = point_cloud.get_axis_aligned_bounding_box()\n",
        "        center = bounding_box.get_center()\n",
        "        extent = bounding_box.get_extent()\n",
        "        render_final_pc.scene.camera.look_at(center, center + [0, 0, 1], [0, 1, 0])\n",
        "        render_final_pc.scene.camera.set_projection(60 / zoom_out_factor, width_final_render / height_final_render, 0.1, 100.0,\n",
        "                                      o3d.visualization.rendering.Camera.FovType.Horizontal)\n",
        "\n",
        "        pc_img = render_final_pc.render_to_image()\n",
        "        output_file = os.path.join(log_dir, f\"{name}_final_render.jpg\")\n",
        "        o3d.io.write_image(output_file, pc_img)\n",
        "        display.stop()\n",
        "\n",
        "\n",
        "def clip_loss(rendered_images, encoded_text, clip_transform, augment_transform, clip_model):\n",
        "    if n_augs == 0:\n",
        "        clip_image = clip_transform(rendered_images)\n",
        "        encoded_renders = clip_model.encode_image(clip_image)\n",
        "        encoded_renders = encoded_renders / encoded_renders.norm(dim=1, keepdim=True)\n",
        "        if encoded_text.shape[0] > 1:\n",
        "            loss = torch.cosine_similarity(torch.mean(encoded_renders, dim=0),\n",
        "                                                torch.mean(encoded_text, dim=0), dim=0)\n",
        "        else:\n",
        "            loss = torch.cosine_similarity(torch.mean(encoded_renders, dim=0, keepdim=True),\n",
        "                                                encoded_text)\n",
        "\n",
        "    elif n_augs > 0:\n",
        "        loss = 1.0 #original 0.0\n",
        "        for _ in range(n_augs):\n",
        "            augmented_image = augment_transform(rendered_images)\n",
        "            encoded_renders = clip_model.encode_image(augmented_image)\n",
        "            if encoded_text.shape[0] > 1:\n",
        "                loss -= torch.cosine_similarity(torch.mean(encoded_renders, dim=0),\n",
        "                                                    torch.mean(encoded_text, dim=0), dim=0)\n",
        "            else:\n",
        "                loss -= torch.cosine_similarity(torch.mean(encoded_renders, dim=0, keepdim=True),\n",
        "                                                    encoded_text)\n",
        "    return loss\n",
        "\n",
        "def save_renders(dir, i, rendered_images, name=None):\n",
        "    if name is not None:\n",
        "        torchvision.utils.save_image(rendered_images, os.path.join(dir, name))\n",
        "    else:\n",
        "        torchvision.utils.save_image(rendered_images, os.path.join(dir, 'renders/iter_{}.jpg'.format(i)))"
      ],
      "metadata": {
        "id": "yXjytggktZyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22527a9-6ee2-4cd9-fb05-5289ab0fd7f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (0.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath) (3.1.1)\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py310_cu121_pyt251/download.html\n",
            "Requirement already satisfied: pytorch3d in /usr/local/lib/python3.10/dist-packages (0.7.8)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "IsWbMWS_wPfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import open3d as o3d\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torch  # If dataset uses PyTorch tensors\n",
        "\n",
        "# Assuming AffordNetDataset is correctly initialized\n",
        "data_dir = \".\"\n",
        "dataset = AffordNetDataset(data_dir=data_dir)\n",
        "print(len(dataset))\n",
        "# Split dataset into test and validation indices\n",
        "indexes = list(range(len(dataset)))\n",
        "val_indexes, test_indexes = train_test_split(indexes, test_size=0.9, shuffle=True)\n",
        "\n",
        "# Create Subsets\n",
        "val_dataset = Subset(dataset, val_indexes)\n",
        "test_dataset = Subset(dataset, test_indexes)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 1  # Load one point cloud at a time for visualization\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# Check dataset sizes\n",
        "print(f\"Valid Dataset Size: {len(val_dataset)}\")\n",
        "print(f\"Test Dataset Size: {len(test_dataset)}\")\n",
        "\n",
        "\n",
        "# Access a sample\n",
        "point_cloud, affordance_labels = dataset[0]\n",
        "\n",
        "print(\"Point Cloud Shape:\", point_cloud.shape)\n",
        "print(\"Affordance Labels Shape:\", affordance_labels.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "_SnyUD5n0s_x",
        "outputId": "45d440b8-c51f-45dd-f110-6b735aa6ddc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of point clouds with 'semantic class' equal to Mug: 133\n",
            "133\n",
            "Valid Dataset Size: 13\n",
            "Test Dataset Size: 120\n",
            "Point Cloud Shape: (2048, 3)\n",
            "Affordance Labels Shape: (2048, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training\n"
      ],
      "metadata": {
        "id": "emSKfuFmrL14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_colors(pred_class, colors, device):\n",
        "    \"\"\"\n",
        "    Assign colors to points based on their probabilities.\n",
        "\n",
        "    Args:\n",
        "        pred_class (torch.Tensor): Tensor of shape [N, 2], where each row contains\n",
        "                                   [p_highlighted, p_not_highlighted].\n",
        "        colors (torch.Tensor): Tensor of shape [2, 3], where the first row is \"highlighter\" color\n",
        "                               and the second row is \"gray\" color.\n",
        "        device (torch.device): Device to which the tensors are moved (e.g., \"cpu\" or \"cuda\").\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor of shape [N, 3] containing the RGB colors for each point.\n",
        "    \"\"\"\n",
        "    # Ensure the probabilities are normalized (if not already)\n",
        "    # pred_class = pred_class / pred_class.sum(dim=1, keepdim=True)\n",
        "\n",
        "    # Extract probabilities for highlighter and gray\n",
        "    p_highlighter = pred_class[:, 0].unsqueeze(1)  # Shape: [N, 1]\n",
        "    p_gray = pred_class[:, 1].unsqueeze(1)         # Shape: [N, 1]\n",
        "\n",
        "\n",
        "\n",
        "    # Compute weighted colors\n",
        "    colors_highlighter = colors[0].unsqueeze(0)  # Shape: [1, 3]\n",
        "    colors_gray = colors[1].unsqueeze(0)        # Shape: [1, 3]\n",
        "\n",
        "\n",
        "    # Weighted sum of the colors based on probabilities\n",
        "    point_colors = p_highlighter * colors_highlighter + p_gray * colors_gray  # Shape: [N, 3]\n",
        "\n",
        "    return point_colors.to(device)"
      ],
      "metadata": {
        "id": "QO2W755G2_9-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rendering Example\n"
      ],
      "metadata": {
        "id": "27og0o0g-mOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "obj_path = 'data/dog.obj'\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#Path(os.path.join(output_dir, 'renders')).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "objbase, extension = os.path.splitext(os.path.basename(obj_path))\n",
        "\n",
        "# list of possible colors\n",
        "rgb_to_color = {(204/255, 1., 0.): \"highlighter\", (180/255, 180/255, 180/255): \"gray\"}\n",
        "color_to_rgb = {\"highlighter\": [204/255, 1., 0.], \"gray\": [180/255, 180/255, 180/255]}\n",
        "full_colors = [[204/255, 1., 0.], [180/255, 180/255, 180/255]]\n",
        "colors = torch.tensor(full_colors).to(device)\n",
        "\n",
        "#------------ MESH TO POINT CLOUD INIT---------------\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "#here we retrieve first the point cloud from the mesh (only for test purpose)\n",
        "mesh_o3d = o3d.io.read_triangle_mesh(obj_path)\n",
        "mesh_o3d.compute_vertex_normals()\n",
        "pcd = mesh_o3d.sample_points_poisson_disk(2048)\n",
        "o3d.io.write_point_cloud(\"dog.pcd\", pcd)\n",
        "display.stop()\n",
        "#------------ MESH TO POINT CLOUD END---------------\n",
        "\n",
        "# Load the point cloud using Open3D\n",
        "pcd = o3d.io.read_point_cloud(\"dog.pcd\")\n",
        "\n",
        "# Extract vertices and colors\n",
        "points = torch.tensor(np.asarray(pcd.points), dtype=torch.float32, device = device)\n",
        "\n",
        "\n",
        "# Create a tensor of gray colors for each point\n",
        "gray_rgb = torch.tensor(color_to_rgb[\"gray\"], dtype=torch.float32, device=device)  # Gray RGB value\n",
        "gray_colors = gray_rgb.unsqueeze(0).repeat(points.shape[0], 1)  # Repeat gray for all points\n",
        "\n",
        "# Assume points.shape[0] is the number of points (N)\n",
        "N = points.shape[0]\n",
        "\n",
        "# Generate random values for the (N, 2) tensor\n",
        "#pred_class = torch.rand(N, 2)\n",
        "\n",
        "if N % 2 != 0:\n",
        "    raise ValueError(\"N must be an even number to split evenly into halves.\")\n",
        "\n",
        "# Create the tensor\n",
        "half_N = N // 2\n",
        "column1 = torch.cat((torch.zeros(half_N), torch.ones(half_N)))\n",
        "column2 = torch.cat((torch.zeros(half_N), torch.ones(half_N)))\n",
        "\n",
        "# Stack columns to form the final tensor\n",
        "pred_class = torch.stack((column1, column2), dim=1)\n",
        "\n",
        "\n",
        "# Normalize along the last dimension to ensure probabilities sum to 1\n",
        "pred_class = pred_class / pred_class.sum(dim=1, keepdim=True)\n",
        "\n",
        "#print(\"probabilites:\", pred_class)\n",
        "\n",
        "point_colors = assign_colors(pred_class.to(device), colors, device)\n",
        "\n",
        "#print(\"Color tensor: \", point_colors)\n",
        "\n",
        "# Create a PyTorch3D Pointclouds object\n",
        "point_cloud = Pointclouds(points=[points], features=[point_colors])\n",
        "\n",
        "# Define multiple camera views\n",
        "num_views = 4\n",
        "elevations = [10, 20, 30, 40]  # Example elevation angles\n",
        "azimuths = [0, 90, 180, 270]   # Example azimuth angles\n",
        "Rs, Ts = zip(*(look_at_view_transform(20, elev, azim) for elev, azim in zip(elevations, azimuths)))\n",
        "\n",
        "# Initialize rasterizer and renderer\n",
        "raster_settings = PointsRasterizationSettings(\n",
        "    image_size=224,\n",
        "    radius=0.003,\n",
        "    points_per_pixel=10\n",
        ")\n",
        "# Initialize variables\n",
        "background = torch.tensor((1., 1., 1.)).to(device)\n",
        "\n",
        "# Render images from multiple views\n",
        "rendered_images = []\n",
        "for R, T in zip(Rs, Ts):\n",
        "    # Create a new camera for the current view\n",
        "    cameras = FoVOrthographicCameras(device=device, R=R, T=T, znear=0.01)\n",
        "\n",
        "    # Initialize the renderer with the new camera\n",
        "    renderer = PulsarPointsRenderer(\n",
        "        rasterizer=PointsRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
        "        n_channels=3\n",
        "    ).to(device)\n",
        "\n",
        "    # Render the image for the current camera view\n",
        "    image = renderer(\n",
        "        point_cloud,\n",
        "        gamma=(1e-4,),\n",
        "        bg_col=background\n",
        "    )\n",
        "    rendered_images.append(image.permute(0,3,1,2))  # Extract RGB channels\n",
        "\n",
        "print(rendered_images[0].shape)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming rendered_images is a list of images (NumPy arrays)\n",
        "num_images = len(rendered_images)\n",
        "\n",
        "# Create a figure and axes for the combined image\n",
        "fig, axes = plt.subplots(1, num_images, figsize=(15, 5))  # Adjust figsize as needed\n",
        "\n",
        "# Iterate through the rendered images and display them on the subplots\n",
        "for i, image in enumerate(rendered_images):\n",
        "    axes[i].imshow(image)\n",
        "    axes[i].axis('off')  # Turn off axis labels and ticks\n",
        "\n",
        "# Display the combined image\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "tJi_6dSl81rG",
        "outputId": "afcd8d3a-5ecc-4bc7-9905-7e4d6659778e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-41478ebca884>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;31m# Iterate through the rendered images and display them on the subplots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrendered_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Turn off axis labels and ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m             return func(\n\u001b[0m\u001b[1;32m   1522\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5943\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5945\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5946\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5947\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_image_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mImage\u001b[0m \u001b[0msubclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"same_kind\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             raise TypeError(f\"Image data of dtype {A.dtype} cannot be \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/cbook.py\u001b[0m in \u001b[0;36msafe_masked_invalid\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;31m# If we have already made a copy, do the byteswap in place, else make a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABMkAAAGyCAYAAAD+jZMxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAO8RJREFUeJzt3X9w1fWdL/5XEkyiUxNxKeFHY6m2Fl0UFEo2Wm+vd1JzV4cuf3SaVQe4XH9cK3SU3LaAIKmlJayrXHZWLCPK0j/qQuso0ylMrE3LdK3Zywhkxt4CDkUarmMCrJeEjW2iyef7R7+mmxJ+nJgfnPN5PGbOH7x5v3Ner4HPy+OTzzknL0mSJAAAAAAgxfJHuwAAAAAAGG1CMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBqTCL3/5y5gzZ05MmjQp8vLyYvv27ec8s2vXrrjxxhujqKgoPv3pT8eWLVuGvU6A/8jsArKR2QVkKyEZkAqdnZ0xffr02LBhw3ntf+utt+KOO+6IW2+9NZqbm+Phhx+Oe++9N15++eVhrhTgT8wuIBuZXUC2ykuSJBntIgBGUl5eXrz00ksxd+7cM+5ZunRp7NixI37961/3rf3t3/5tnDx5MhoaGkagSoD+zC4gG5ldQDYZM9oFAFyImpqaoqqqqt9adXV1PPzww2c809XVFV1dXX2/7u3tjXfffTf+4i/+IvLy8oarVOACkSRJnDp1KiZNmhT5+aNzs77ZBWQqW2dXhPkFaTZcs0tIBjCA1tbWKCsr67dWVlYWHR0d8fvf/z4uvvji087U19fHY489NlIlAheoo0ePxic+8YlReW6zCxisbJtdEeYXMPSzS0gGMESWL18etbW1fb9ub2+PK664Io4ePRolJSWjWBkwEjo6OqK8vDwuvfTS0S4lI2YXpFu2zq4I8wvSbLhml5AMYAATJkyItra2fmttbW1RUlJyxn/NLCoqiqKiotPWS0pKvFCDFBnNt/iYXcBgZdvsijC/gKGfXb7dEmAAlZWV0djY2G/tlVdeicrKylGqCODczC4gG5ldwIVCSAakwr//+79Hc3NzNDc3R8Qfv2q8ubk5WlpaIuKPt+vPnz+/b/8DDzwQhw8fjm9+85tx4MCBePrpp+OHP/xhLFmyZDTKB1LK7AKykdkFZCshGZAKr7/+etxwww1xww03REREbW1t3HDDDbFq1aqIiHjnnXf6XrhFRHzqU5+KHTt2xCuvvBLTp0+PJ598Mp599tmorq4elfqBdDK7gGxkdgHZKi9JkmS0iwDIRR0dHVFaWhrt7e0+FwNSIFeu+VzpAzg/uXTN51IvwNkN1/XuTjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNTLOCT75S9/GXPmzIlJkyZFXl5ebN++/Zxndu3aFTfeeGMUFRXFpz/96diyZcsgSgUAAACA4ZFxSNbZ2RnTp0+PDRs2nNf+t956K+6444649dZbo7m5OR5++OG499574+WXX864WAAAAAAYDmMyPfDXf/3X8dd//dfnvX/jxo3xqU99Kp588smIiLjmmmvi1Vdfjf/1v/5XVFdXZ/r0AAAAADDkMg7JMtXU1BRVVVX91qqrq+Phhx8+45murq7o6urq+3Vvb2+8++678Rd/8ReRl5c3XKUCF4AkSeLUqVMxadKkyM/3sYkAAACMjGEPyVpbW6OsrKzfWllZWXR0dMTvf//7uPjii087U19fH4899thwlwZcwI4ePRqf+MQnRrsMAAAAUmLYQ7LBWL58edTW1vb9ur29Pa644oo4evRolJSUjGJlwHDr6OiI8vLyuPTSS0e7FAAAAFJk2EOyCRMmRFtbW7+1tra2KCkpGfAusoiIoqKiKCoqOm29pKRESAYp4a3VAAAAjKRh/8CfysrKaGxs7Lf2yiuvRGVl5XA/NQAAAACcl4xDsn//93+P5ubmaG5ujoiIt956K5qbm6OlpSUi/vhWyfnz5/ftf+CBB+Lw4cPxzW9+Mw4cOBBPP/10/PCHP4wlS5YMTQcAAAAA8BFlHJK9/vrrccMNN8QNN9wQERG1tbVxww03xKpVqyIi4p133ukLzCIiPvWpT8WOHTvilVdeienTp8eTTz4Zzz77bFRXVw9RCwAAAADw0WT8mWT/+T//50iS5Iy/v2XLlgHP7Nu3L9OnAgAAAIARMeyfSQZwodiwYUNMmTIliouLo6KiInbv3n3W/evXr4/PfvazcfHFF0d5eXksWbIk/vCHP4xQtQB/ZHYB2cr8ArKNkAxIhW3btkVtbW3U1dXF3r17Y/r06VFdXR3Hjh0bcP/zzz8fy5Yti7q6uti/f38899xzsW3btnjkkUdGuHIgzcwuIFuZX0A2EpIBqbBu3bq47777YuHChXHttdfGxo0b45JLLonNmzcPuP+1116Lm2++Oe66666YMmVK3HbbbXHnnXee819AAYaS2QVkK/MLyEZCMiDndXd3x549e6KqqqpvLT8/P6qqqqKpqWnAMzfddFPs2bOn74XZ4cOHY+fOnXH77bef8Xm6urqio6Oj3wNgsMwuIFuZX0C2yviD+wGyzYkTJ6KnpyfKysr6rZeVlcWBAwcGPHPXXXfFiRMn4vOf/3wkSRIffPBBPPDAA2e95b++vj4ee+yxIa0dSC+zC8hW5heQrdxJBjCAXbt2xZo1a+Lpp5+OvXv3xosvvhg7duyI1atXn/HM8uXLo729ve9x9OjREawYwOwCspf5BVwI3EkG5Lxx48ZFQUFBtLW19Vtva2uLCRMmDHjm0UcfjXnz5sW9994bERHXXXdddHZ2xv333x8rVqyI/PzT/42hqKgoioqKhr4BIJXMLiBbmV9AtnInGZDzCgsLY+bMmdHY2Ni31tvbG42NjVFZWTngmffee++0F2MFBQUREZEkyfAVC/D/M7uAbGV+AdnKnWRAKtTW1saCBQti1qxZMXv27Fi/fn10dnbGwoULIyJi/vz5MXny5Kivr4+IiDlz5sS6devihhtuiIqKijh06FA8+uijMWfOnL4XbADDzewCspX5BWQjIRmQCjU1NXH8+PFYtWpVtLa2xowZM6KhoaHvA2VbWlr6/evlypUrIy8vL1auXBlvv/12fPzjH485c+bEd7/73dFqAUghswvIVuYXkI3ykiy4d7WjoyNKS0ujvb09SkpKRrscYBjl0vWeS70A55Yr13yu9AGcn1y65nOpF+Dshut695lkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqDSok27BhQ0yZMiWKi4ujoqIidu/efdb969evj89+9rNx8cUXR3l5eSxZsiT+8Ic/DKpgAAAAABhqGYdk27Zti9ra2qirq4u9e/fG9OnTo7q6Oo4dOzbg/ueffz6WLVsWdXV1sX///njuuedi27Zt8cgjj3zk4gEAAABgKGQckq1bty7uu+++WLhwYVx77bWxcePGuOSSS2Lz5s0D7n/ttdfi5ptvjrvuuiumTJkSt912W9x5553nvPsMAAAAAEZKRiFZd3d37NmzJ6qqqv70A/Lzo6qqKpqamgY8c9NNN8WePXv6QrHDhw/Hzp074/bbbz/j83R1dUVHR0e/BwAAAAAMlzGZbD5x4kT09PREWVlZv/WysrI4cODAgGfuuuuuOHHiRHz+85+PJEnigw8+iAceeOCsb7esr6+Pxx57LJPSAAAAAGDQhv3bLXft2hVr1qyJp59+Ovbu3Rsvvvhi7NixI1avXn3GM8uXL4/29va+x9GjR4e7TAAAAABSLKM7ycaNGxcFBQXR1tbWb72trS0mTJgw4JlHH3005s2bF/fee29ERFx33XXR2dkZ999/f6xYsSLy80/P6YqKiqKoqCiT0gAAAABg0DK6k6ywsDBmzpwZjY2NfWu9vb3R2NgYlZWVA5557733TgvCCgoKIiIiSZJM6wUAAACAIZfRnWQREbW1tbFgwYKYNWtWzJ49O9avXx+dnZ2xcOHCiIiYP39+TJ48Oerr6yMiYs6cObFu3bq44YYboqKiIg4dOhSPPvpozJkzpy8sAwAAAIDRlHFIVlNTE8ePH49Vq1ZFa2trzJgxIxoaGvo+zL+lpaXfnWMrV66MvLy8WLlyZbz99tvx8Y9/PObMmRPf/e53h64LAAAAAPgI8pIseM9jR0dHlJaWRnt7e5SUlIx2OcAwyqXrPZd6Ac4tV675XOkDOD+5dM3nUi/A2Q3X9T7s324JAAAAABc6IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckA1Jjw4YNMWXKlCguLo6KiorYvXv3WfefPHkyFi1aFBMnToyioqK4+uqrY+fOnSNULcAfmV1AtjK/gGwzZrQLABgJ27Zti9ra2ti4cWNUVFTE+vXro7q6Og4ePBjjx48/bX93d3d88YtfjPHjx8cLL7wQkydPjt/97ndx2WWXjXzxQGqZXUC2Mr+AbJSXJEky2kWcS0dHR5SWlkZ7e3uUlJSMdjnAMBqu672ioiI+97nPxVNPPRUREb29vVFeXh5f+9rXYtmyZaft37hxY/z93/99HDhwIC666KJBPafZBekyHNe82QUMN6+9gGw0XNe7t1sCOa+7uzv27NkTVVVVfWv5+flRVVUVTU1NA5758Y9/HJWVlbFo0aIoKyuLadOmxZo1a6Knp+eMz9PV1RUdHR39HgCDZXYB2cr8ArKVkAzIeSdOnIienp4oKyvrt15WVhatra0Dnjl8+HC88MIL0dPTEzt37oxHH300nnzyyfjOd75zxuepr6+P0tLSvkd5efmQ9gGki9kFZCvzC8hWQjKAAfT29sb48ePjmWeeiZkzZ0ZNTU2sWLEiNm7ceMYzy5cvj/b29r7H0aNHR7BiALMLyF7mF3Ah8MH9QM4bN25cFBQURFtbW7/1tra2mDBhwoBnJk6cGBdddFEUFBT0rV1zzTXR2toa3d3dUVhYeNqZoqKiKCoqGtrigdQyu4BsZX4B2cqdZEDOKywsjJkzZ0ZjY2PfWm9vbzQ2NkZlZeWAZ26++eY4dOhQ9Pb29q29+eabMXHixAFfpAEMNbMLyFbmF5CthGRAKtTW1samTZvi+9//fuzfvz+++tWvRmdnZyxcuDAiIubPnx/Lly/v2//Vr3413n333XjooYfizTffjB07dsSaNWti0aJFo9UCkEJmF5CtzC8gG3m7JZAKNTU1cfz48Vi1alW0trbGjBkzoqGhoe8DZVtaWiI//0//blBeXh4vv/xyLFmyJK6//vqYPHlyPPTQQ7F06dLRagFIIbMLyFbmF5CN8pIkSUa7iHPp6OiI0tLSaG9vj5KSktEuBxhGuXS951IvwLnlyjWfK30A5yeXrvlc6gU4u+G63r3dEgAAAIDUE5IBAAAAkHqDCsk2bNgQU6ZMieLi4qioqIjdu3efdf/Jkydj0aJFMXHixCgqKoqrr746du7cOaiCAQAAAGCoZfzB/du2bYva2trYuHFjVFRUxPr166O6ujoOHjwY48ePP21/d3d3fPGLX4zx48fHCy+8EJMnT47f/e53cdlllw1F/QAAAADwkWUckq1bty7uu+++vq/u3bhxY+zYsSM2b94cy5YtO23/5s2b4913343XXnstLrroooiImDJlykerGgAAAACGUEZvt+zu7o49e/ZEVVXVn35Afn5UVVVFU1PTgGd+/OMfR2VlZSxatCjKyspi2rRpsWbNmujp6flolQMAAADAEMnoTrITJ05ET09PlJWV9VsvKyuLAwcODHjm8OHD8fOf/zzuvvvu2LlzZxw6dCgefPDBeP/996Ourm7AM11dXdHV1dX3646OjkzKBAAAAICMDPu3W/b29sb48ePjmWeeiZkzZ0ZNTU2sWLEiNm7ceMYz9fX1UVpa2vcoLy8f7jIBAAAASLGMQrJx48ZFQUFBtLW19Vtva2uLCRMmDHhm4sSJcfXVV0dBQUHf2jXXXBOtra3R3d094Jnly5dHe3t73+Po0aOZlAkAAAAAGckoJCssLIyZM2dGY2Nj31pvb280NjZGZWXlgGduvvnmOHToUPT29vatvfnmmzFx4sQoLCwc8ExRUVGUlJT0ewAAAADAcMn47Za1tbWxadOm+P73vx/79++Pr371q9HZ2dn3bZfz58+P5cuX9+3/6le/Gu+++2489NBD8eabb8aOHTtizZo1sWjRoqHrAgAAAAA+gow+uD8ioqamJo4fPx6rVq2K1tbWmDFjRjQ0NPR9mH9LS0vk5/8peysvL4+XX345lixZEtdff31Mnjw5HnrooVi6dOnQdQEAAAAAH0HGIVlExOLFi2Px4sUD/t6uXbtOW6usrIx//dd/HcxTAQAAAMCwG/ZvtwQAAACAC52QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPUGFZJt2LAhpkyZEsXFxVFRURG7d+8+r3Nbt26NvLy8mDt37mCeFgAAAACGRcYh2bZt26K2tjbq6upi7969MX369Kiuro5jx46d9dyRI0fi61//etxyyy2DLhYAAAAAhkPGIdm6devivvvui4ULF8a1114bGzdujEsuuSQ2b958xjM9PT1x9913x2OPPRZXXnnlRyoYAAAAAIZaRiFZd3d37NmzJ6qqqv70A/Lzo6qqKpqams547tvf/naMHz8+7rnnnvN6nq6urujo6Oj3AAAAAIDhklFIduLEiejp6YmysrJ+62VlZdHa2jrgmVdffTWee+652LRp03k/T319fZSWlvY9ysvLMykTAAAAADIyrN9ueerUqZg3b15s2rQpxo0bd97nli9fHu3t7X2Po0ePDmOVAAAAAKTdmEw2jxs3LgoKCqKtra3feltbW0yYMOG0/b/97W/jyJEjMWfOnL613t7ePz7xmDFx8ODBuOqqq047V1RUFEVFRZmUBgAAAACDltGdZIWFhTFz5sxobGzsW+vt7Y3GxsaorKw8bf/UqVPjjTfeiObm5r7Hl770pbj11lujubnZ2ygBAAAAuCBkdCdZRERtbW0sWLAgZs2aFbNnz47169dHZ2dnLFy4MCIi5s+fH5MnT476+vooLi6OadOm9Tt/2WWXRUSctg4AAAAAoyXjkKympiaOHz8eq1atitbW1pgxY0Y0NDT0fZh/S0tL5OcP60edAQAAAMCQyjgki4hYvHhxLF68eMDf27Vr11nPbtmyZTBPCQAAAADDxi1fAAAAAKSekAwAAACA1BOSAamxYcOGmDJlShQXF0dFRUXs3r37vM5t3bo18vLyYu7cucNbIMAZmF9ANjK7gGwjJANSYdu2bVFbWxt1dXWxd+/emD59elRXV8exY8fOeu7IkSPx9a9/PW655ZYRqhSgP/MLyEZmF5CNhGRAKqxbty7uu+++WLhwYVx77bWxcePGuOSSS2Lz5s1nPNPT0xN33313PPbYY3HllVeOYLUAf2J+AdnI7AKykZAMyHnd3d2xZ8+eqKqq6lvLz8+PqqqqaGpqOuO5b3/72zF+/Pi45557zut5urq6oqOjo98D4KMYiflldgFDzWsvIFsJyYCcd+LEiejp6YmysrJ+62VlZdHa2jrgmVdffTWee+652LRp03k/T319fZSWlvY9ysvLP1LdACMxv8wuYKh57QVkKyEZwJ85depUzJs3LzZt2hTjxo0773PLly+P9vb2vsfRo0eHsUqA0w1mfpldwGjz2gu4UIwZ7QIAhtu4ceOioKAg2tra+q23tbXFhAkTTtv/29/+No4cORJz5szpW+vt7Y2IiDFjxsTBgwfjqquuOu1cUVFRFBUVDXH1QJqNxPwyu4Ch5rUXkK3cSQbkvMLCwpg5c2Y0Njb2rfX29kZjY2NUVlaetn/q1KnxxhtvRHNzc9/jS1/6Utx6663R3NzsVn5gxJhfQDYyu4Bs5U4yIBVqa2tjwYIFMWvWrJg9e3asX78+Ojs7Y+HChRERMX/+/Jg8eXLU19dHcXFxTJs2rd/5yy67LCLitHWA4WZ+AdnI7AKykZAMSIWampo4fvx4rFq1KlpbW2PGjBnR0NDQ94GyLS0tkZ/v5lrgwmN+AdnI7AKyUV6SJMloF3EuHR0dUVpaGu3t7VFSUjLa5QDDKJeu91zqBTi3XLnmc6UP4Pzk0jWfS70AZzdc17voHgAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHqDCsk2bNgQU6ZMieLi4qioqIjdu3efce+mTZvilltuibFjx8bYsWOjqqrqrPsBAAAAYKRlHJJt27Ytamtro66uLvbu3RvTp0+P6urqOHbs2ID7d+3aFXfeeWf84he/iKampigvL4/bbrst3n777Y9cPAAAAAAMhYxDsnXr1sV9990XCxcujGuvvTY2btwYl1xySWzevHnA/T/4wQ/iwQcfjBkzZsTUqVPj2Wefjd7e3mhsbPzIxQMAAADAUMgoJOvu7o49e/ZEVVXVn35Afn5UVVVFU1PTef2M9957L95///24/PLLM6sUAAAAAIbJmEw2nzhxInp6eqKsrKzfellZWRw4cOC8fsbSpUtj0qRJ/YK2P9fV1RVdXV19v+7o6MikTAAAAADIyIh+u+XatWtj69at8dJLL0VxcfEZ99XX10dpaWnfo7y8fASrBAAAACBtMgrJxo0bFwUFBdHW1tZvva2tLSZMmHDWs0888USsXbs2fvrTn8b1119/1r3Lly+P9vb2vsfRo0czKRMAAAAAMpJRSFZYWBgzZ87s96H7H34If2Vl5RnPPf7447F69epoaGiIWbNmnfN5ioqKoqSkpN8DAAAAAIZLRp9JFhFRW1sbCxYsiFmzZsXs2bNj/fr10dnZGQsXLoyIiPnz58fkyZOjvr4+IiL+7u/+LlatWhXPP/98TJkyJVpbWyMi4mMf+1h87GMfG8JWAAAAAGBwMg7Jampq4vjx47Fq1apobW2NGTNmRENDQ9+H+be0tER+/p9uUPve974X3d3d8eUvf7nfz6mrq4tvfetbH616AAAAABgCGYdkERGLFy+OxYsXD/h7u3bt6vfrI0eODOYpAAAAAGDEjOi3WwIAAADAhUhIBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZEBqbNiwIaZMmRLFxcVRUVERu3fvPuPeTZs2xS233BJjx46NsWPHRlVV1Vn3Awwn8wvIRmYXkG2EZEAqbNu2LWpra6Ouri727t0b06dPj+rq6jh27NiA+3ft2hV33nln/OIXv4impqYoLy+P2267Ld5+++0RrhxIO/MLyEZmF5CN8pIkSUa7iHPp6OiI0tLSaG9vj5KSktEuBxhGw3W9V1RUxOc+97l46qmnIiKit7c3ysvL42tf+1osW7bsnOd7enpi7Nix8dRTT8X8+fPP6znNLkiXXJlfZhekS67MrgjzC9JkuK53d5IBOa+7uzv27NkTVVVVfWv5+flRVVUVTU1N5/Uz3nvvvXj//ffj8ssvP+Oerq6u6Ojo6PcA+ChGYn6ZXcBQ89oLyFZCMiDnnThxInp6eqKsrKzfellZWbS2tp7Xz1i6dGlMmjSp34u9P1dfXx+lpaV9j/Ly8o9UN8BIzC+zCxhqXnsB2UpIBnAOa9euja1bt8ZLL70UxcXFZ9y3fPnyaG9v73scPXp0BKsEON35zC+zC7jQeO0FjJYxo10AwHAbN25cFBQURFtbW7/1tra2mDBhwlnPPvHEE7F27dr42c9+Ftdff/1Z9xYVFUVRUdFHrhfgQyMxv8wuYKh57QVkK3eSATmvsLAwZs6cGY2NjX1rvb290djYGJWVlWc89/jjj8fq1aujoaEhZs2aNRKlAvRjfgHZyOwCspU7yYBUqK2tjQULFsSsWbNi9uzZsX79+ujs7IyFCxdGRMT8+fNj8uTJUV9fHxERf/d3fxerVq2K559/PqZMmdL3+Rkf+9jH4mMf+9io9QGkj/kFZCOzC8hGQjIgFWpqauL48eOxatWqaG1tjRkzZkRDQ0PfB8q2tLREfv6fbq793ve+F93d3fHlL3+538+pq6uLb33rWyNZOpBy5heQjcwuIBvlJUmSjHYR59LR0RGlpaXR3t4eJSUlo10OMIxy6XrPpV6Ac8uVaz5X+gDOTy5d87nUC3B2w3W9D+ozyTZs2BBTpkyJ4uLiqKioiN27d591/49+9KOYOnVqFBcXx3XXXRc7d+4cVLEAAAAAMBwyDsm2bdsWtbW1UVdXF3v37o3p06dHdXV1HDt2bMD9r732Wtx5551xzz33xL59+2Lu3Lkxd+7c+PWvf/2RiwcAAACAoZBxSLZu3bq47777YuHChXHttdfGxo0b45JLLonNmzcPuP8f/uEf4r/+1/8a3/jGN+Kaa66J1atXx4033hhPPfXURy4eAAAAAIZCRh/c393dHXv27Inly5f3reXn50dVVVU0NTUNeKapqSlqa2v7rVVXV8f27dvP+DxdXV3R1dXV9+v29vaI+ON7ToHc9uF1ngUflwgAAEAOySgkO3HiRPT09PR9I8mHysrK4sCBAwOeaW1tHXD/h1/pO5D6+vp47LHHTlsvLy/PpFwgi/3bv/1blJaWjnYZAAAApERGIdlIWb58eb+7z06ePBmf/OQno6WlJav/p7mjoyPKy8vj6NGjWf9tK7nSS670EZE7vbS3t8cVV1wRl19++WiXAgAAQIpkFJKNGzcuCgoKoq2trd96W1tbTJgwYcAzEyZMyGh/RERRUVEUFRWdtl5aWprV//P/oZKSkpzoIyJ3esmVPiJyp5f8/EF9+S4AAAAMSkb/F1pYWBgzZ86MxsbGvrXe3t5obGyMysrKAc9UVlb22x8R8corr5xxPwAAAACMtIzfbllbWxsLFiyIWbNmxezZs2P9+vXR2dkZCxcujIiI+fPnx+TJk6O+vj4iIh566KH4whe+EE8++WTccccdsXXr1nj99dfjmWeeGdpOAAAAAGCQMg7Jampq4vjx47Fq1apobW2NGTNmRENDQ9+H87e0tPR7m9RNN90Uzz//fKxcuTIeeeSR+MxnPhPbt2+PadOmnfdzFhUVRV1d3YBvwcwmudJHRO70kit9ROROL7nSBwAAANklL0mSZLSLAMhFHR0dUVpaGu3t7TnxOXHA2eXKNZ8rfQDnJ5eu+VzqBTi74brefTI2AAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1LtgQrINGzbElClTori4OCoqKmL37t1n3f+jH/0opk6dGsXFxXHdddfFzp07R6jSs8ukj02bNsUtt9wSY8eOjbFjx0ZVVdU5+x5Jmf6ZfGjr1q2Rl5cXc+fOHd4Cz1OmfZw8eTIWLVoUEydOjKKiorj66quz8u9XRMT69evjs5/9bFx88cVRXl4eS5YsiT/84Q8jVO3AfvnLX8acOXNi0qRJkZeXF9u3bz/nmV27dsWNN94YRUVF8elPfzq2bNky7HUCAACQLhdESLZt27aora2Nurq62Lt3b0yfPj2qq6vj2LFjA+5/7bXX4s4774x77rkn9u3bF3Pnzo25c+fGr3/96xGuvL9M+9i1a1fceeed8Ytf/CKampqivLw8brvttnj77bdHuPLTZdrLh44cORJf//rX45ZbbhmhSs8u0z66u7vji1/8Yhw5ciReeOGFOHjwYGzatCkmT548wpWfLtNenn/++Vi2bFnU1dXF/v3747nnnott27bFI488MsKV99fZ2RnTp0+PDRs2nNf+t956K+6444649dZbo7m5OR5++OG499574+WXXx7mSgEAAEiTvCRJktEuoqKiIj73uc/FU089FRERvb29UV5eHl/72tdi2bJlp+2vqamJzs7O+MlPftK39ld/9VcxY8aM2Lhx44jV/ecy7ePP9fT0xNixY+Opp56K+fPnD3e5ZzWYXnp6euI//af/FP/9v//3+Jd/+Zc4efLked0lNJwy7WPjxo3x93//93HgwIG46KKLRrrcs8q0l8WLF8f+/fujsbGxb+1//s//Gf/7f//vePXVV0es7rPJy8uLl1566ax3HS5dujR27NjRLwT/27/92zh58mQ0NDSMQJWD52vIIV1y5ZrPlT6A85NL13wu9QKc3XBd76N+J1l3d3fs2bMnqqqq+tby8/OjqqoqmpqaBjzT1NTUb39ERHV19Rn3j4TB9PHn3nvvvXj//ffj8ssvH64yz8tge/n2t78d48ePj3vuuWckyjynwfTx4x//OCorK2PRokVRVlYW06ZNizVr1kRPT89IlT2gwfRy0003xZ49e/reknn48OHYuXNn3H777SNS81C5EK93AAAAcs+Y0S7gxIkT0dPTE2VlZf3Wy8rK4sCBAwOeaW1tHXB/a2vrsNV5LoPp488tXbo0Jk2adFogMNIG08urr74azz33XDQ3N49AhednMH0cPnw4fv7zn8fdd98dO3fujEOHDsWDDz4Y77//ftTV1Y1E2QMaTC933XVXnDhxIj7/+c9HkiTxwQcfxAMPPDDqb7fM1Jmu946Ojvj9738fF1988ShVBgAAQC4Z9TvJ+KO1a9fG1q1b46WXXori4uLRLicjp06dinnz5sWmTZti3Lhxo13OR9Lb2xvjx4+PZ555JmbOnBk1NTWxYsWKUX0b72Dt2rUr1qxZE08//XTs3bs3XnzxxdixY0esXr16tEsDAACAC86o30k2bty4KCgoiLa2tn7rbW1tMWHChAHPTJgwIaP9I2EwfXzoiSeeiLVr18bPfvazuP7664ezzPOSaS+//e1v48iRIzFnzpy+td7e3oiIGDNmTBw8eDCuuuqq4S16AIP5M5k4cWJcdNFFUVBQ0Ld2zTXXRGtra3R3d0dhYeGw1nwmg+nl0UcfjXnz5sW9994bERHXXXdddHZ2xv333x8rVqyI/PzsyMjPdL2XlJS4iwwAAIAhM+r/l1xYWBgzZ87s9+Hivb290djYGJWVlQOeqays7Lc/IuKVV1454/6RMJg+IiIef/zxWL16dTQ0NMSsWbNGotRzyrSXqVOnxhtvvBHNzc19jy996Ut930ZYXl4+kuX3Gcyfyc033xyHDh3qC/kiIt58882YOHHiqAVkEYPr5b333jstCPsw/LsAvq/jvF2I1zsAAAA5KLkAbN26NSkqKkq2bNmS/OY3v0nuv//+5LLLLktaW1uTJEmSefPmJcuWLevb/6tf/SoZM2ZM8sQTTyT79+9P6urqkosuuih54403RquFJEky72Pt2rVJYWFh8sILLyTvvPNO3+PUqVOj1UKfTHv5cwsWLEj+5m/+ZoSqPbNM+2hpaUkuvfTSZPHixcnBgweTn/zkJ8n48eOT73znO6PVQp9Me6mrq0suvfTS5J//+Z+Tw4cPJz/96U+Tq666KvnKV74yWi0kSZIkp06dSvbt25fs27cviYhk3bp1yb59+5Lf/e53SZIkybJly5J58+b17T98+HByySWXJN/4xjeS/fv3Jxs2bEgKCgqShoaG0WrhvLW3tycRkbS3t492KcAIyJVrPlf6AM5PLl3zudQLcHbDdb2P+tstIyJqamri+PHjsWrVqmhtbY0ZM2ZEQ0ND34d1t7S09Lsj5qabbornn38+Vq5cGY888kh85jOfie3bt8e0adNGq4WIyLyP733ve9Hd3R1f/vKX+/2curq6+Na3vjWSpZ8m014uVJn2UV5eHi+//HIsWbIkrr/++pg8eXI89NBDsXTp0tFqoU+mvaxcuTLy8vJi5cqV8fbbb8fHP/7xmDNnTnz3u98drRYiIuL111+PW2+9te/XtbW1ERGxYMGC2LJlS7zzzjvR0tLS9/uf+tSnYseOHbFkyZL4h3/4h/jEJz4Rzz77bFRXV4947QAAAOSuvCTJovddAWSRjo6OKC0tjfb29igpKRntcoBhlivXfK70AZyfXLrmc6kX4OyG63q/8G8FAgAAAIBhJiQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZAAAAAKknJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjIAAAAAUk9IBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1hGQAAAAApJ6QDAAAAIDUE5IBAAAAkHpCMgAAAABST0gGAAAAQOoJyQAAAABIPSEZkBobNmyIKVOmRHFxcVRUVMTu3bvPuv9HP/pRTJ06NYqLi+O6666LnTt3jlClAP2ZX0A2MruAbCMkA1Jh27ZtUVtbG3V1dbF3796YPn16VFdXx7Fjxwbc/9prr8Wdd94Z99xzT+zbty/mzp0bc+fOjV//+tcjXDmQduYXkI3MLiAb5SVJkox2EQDDraKiIj73uc/FU089FRERvb29UV5eHl/72tdi2bJlp+2vqamJzs7O+MlPftK39ld/9VcxY8aM2Lhx43k9Z0dHR5SWlkZ7e3uUlJQMTSPABWu4rvmRnl9mF6RLrsyuCPML0mS4rvcxQ/aTAC5Q3d3dsWfPnli+fHnfWn5+flRVVUVTU9OAZ5qamqK2trbfWnV1dWzfvv2Mz9PV1RVdXV19v25vb4+IPw5wIPd9eK0P5b8/jsT8Mrsg3bJ1dkWYX5BmwzG7IoRkQAqcOHEienp6oqysrN96WVlZHDhwYMAzra2tA+5vbW094/PU19fHY489dtp6eXn5IKoGstW//du/RWlp6ZD8rJGYX2YXEJF9syvC/AKGdnZFCMkAhszy5cv7/QvoyZMn45Of/GS0tLQM6eAeDR0dHVFeXh5Hjx7N6rcv5EofEbnTS670EfHHOxiuuOKKuPzyy0e7lIyYXRe+XOkjInd6yZU+IrJ3dkXk7vzKpb9fudJLrvQRkTu9DNfsEpIBOW/cuHFRUFAQbW1t/dbb2tpiwoQJA56ZMGFCRvsjIoqKiqKoqOi09dLS0qz+D9B/VFJSkhO95EofEbnTS670EfHHtxQNlZGYX2ZX9siVPiJyp5dc6SMi+2ZXRO7Pr1z6+5UrveRKHxG508tQzq4I324JpEBhYWHMnDkzGhsb+9Z6e3ujsbExKisrBzxTWVnZb39ExCuvvHLG/QDDwfwCspHZBWQrd5IBqVBbWxsLFiyIWbNmxezZs2P9+vXR2dkZCxcujIiI+fPnx+TJk6O+vj4iIh566KH4whe+EE8++WTccccdsXXr1nj99dfjmWeeGc02gBQyv4BsZHYB2UhIBqRCTU1NHD9+PFatWhWtra0xY8aMaGho6PuA2JaWln636t50003x/PPPx8qVK+ORRx6Jz3zmM7F9+/aYNm3aeT9nUVFR1NXVDfg2gGyTK73kSh8RudNLrvQRMXy9jPT88mdy4cmVPiJyp5dc6SMid2bXcPYy0nKlj4jc6SVX+ojInV6Gq4+8ZKi/LxMAAAAAsozPJAMAAAAg9YRkAAAAAKSekAwAAACA1BOSAQAAAJB6QjKAj2DDhg0xZcqUKC4ujoqKiti9e/dZ9//oRz+KqVOnRnFxcVx33XWxc+fOEar07DLpY9OmTXHLLbfE2LFjY+zYsVFVVXXOvkdSpn8mH9q6dWvk5eXF3Llzh7fA85RpHydPnoxFixbFxIkTo6ioKK6++uqs/PsVEbF+/fr47Gc/GxdffHGUl5fHkiVL4g9/+MMIVTuwX/7ylzFnzpyYNGlS5OXlxfbt2895ZteuXXHjjTdGUVFRfPrTn44tW7YMe53nK1dmV0TuzK9cmV0RuTO/cmF2ReTW/DK7LrzZFZE78ytXZldEbsyvUZtdCQCDsnXr1qSwsDDZvHlz8n/+z/9J7rvvvuSyyy5L2traBtz/q1/9KikoKEgef/zx5De/+U2ycuXK5KKLLkreeOONEa68v0z7uOuuu5INGzYk+/btS/bv35/8t//235LS0tLk//7f/zvClZ8u014+9NZbbyWTJ09ObrnlluRv/uZvRqbYs8i0j66urmTWrFnJ7bffnrz66qvJW2+9lezatStpbm4e4cpPl2kvP/jBD5KioqLkBz/4QfLWW28lL7/8cjJx4sRkyZIlI1x5fzt37kxWrFiRvPjii0lEJC+99NJZ9x8+fDi55JJLktra2uQ3v/lN8o//+I9JQUFB0tDQMDIFn0WuzK4kyZ35lSuzK0lyZ37lyuxKktyZX2bXhTe7kiR35leuzK4kyZ35NVqzS0gGMEizZ89OFi1a1Pfrnp6eZNKkSUl9ff2A+7/yla8kd9xxR7+1ioqK5H/8j/8xrHWeS6Z9/LkPPvggufTSS5Pvf//7w1XieRtMLx988EFy0003Jc8++2yyYMGCC+KFWqZ9fO9730uuvPLKpLu7e6RKPG+Z9rJo0aLkv/yX/9Jvrba2Nrn55puHtc5MnM8LtW9+85vJX/7lX/Zbq6mpSaqrq4exsvOTK7MrSXJnfuXK7EqS3JlfuTi7kiS755fZ9ScXyuxKktyZX7kyu5IkN+fXSM4ub7cEGITu7u7Ys2dPVFVV9a3l5+dHVVVVNDU1DXimqamp3/6IiOrq6jPuHwmD6ePPvffee/H+++/H5ZdfPlxlnpfB9vLtb387xo8fH/fcc89IlHlOg+njxz/+cVRWVsaiRYuirKwspk2bFmvWrImenp6RKntAg+nlpptuij179vS9LeDw4cOxc+fOuP3220ek5qFyIV7vEbkzuyJyZ37lyuyKyJ35lebZFXFhXvNmV38XwuyKyJ35lSuzKyLd82uorvkxQ1kUQFqcOHEienp6oqysrN96WVlZHDhwYMAzra2tA+5vbW0dtjrPZTB9/LmlS5fGpEmTTvuP0kgbTC+vvvpqPPfcc9Hc3DwCFZ6fwfRx+PDh+PnPfx5333137Ny5Mw4dOhQPPvhgvP/++1FXVzcSZQ9oML3cddddceLEifj85z8fSZLEBx98EA888EA88sgjI1HykDnT9d7R0RG///3v4+KLLx6VunJldkXkzvzKldkVkTvzK82zK+LCnF9mV38XwuyKyJ35lSuzKyLd82uoZpc7yQAYtLVr18bWrVvjpZdeiuLi4tEuJyOnTp2KefPmxaZNm2LcuHGjXc5H0tvbG+PHj49nnnkmZs6cGTU1NbFixYrYuHHjaJeWsV27dsWaNWvi6aefjr1798aLL74YO3bsiNWrV492aeSYbJ1fuTS7InJnfpldjJRsnV0RuTW/cmV2RZhff86dZACDMG7cuCgoKIi2trZ+621tbTFhwoQBz0yYMCGj/SNhMH186Iknnoi1a9fGz372s7j++uuHs8zzkmkvv/3tb+PIkSMxZ86cvrXe3t6IiBgzZkwcPHgwrrrqquEtegCD+TOZOHFiXHTRRVFQUNC3ds0110Rra2t0d3dHYWHhsNZ8JoPp5dFHH4158+bFvffeGxER1113XXR2dsb9998fK1asiPz87Pj3vTNd7yUlJaN2F1lE7syuiNyZX7kyuyJyZ36leXZFXJjzy+z6owtpdkXkzvzKldkVke75NVSzKzu6BbjAFBYWxsyZM6OxsbFvrbe3NxobG6OysnLAM5WVlf32R0S88sorZ9w/EgbTR0TE448/HqtXr46GhoaYNWvWSJR6Tpn2MnXq1HjjjTeiubm57/GlL30pbr311mhubo7y8vKRLL/PYP5Mbr755jh06FDfC82IiDfffDMmTpw4ai/SIgbXy3vvvXfai7EPX4D+8XNbs8OFeL1H5M7sisid+ZUrsysid+ZXmmdXxIV5zZtdF97sisid+ZUrsysi3fNryK75jD7mH4A+W7duTYqKipItW7Ykv/nNb5L7778/ueyyy5LW1tYkSZJk3rx5ybJly/r2/+pXv0rGjBmTPPHEE8n+/fuTurq6C+KryDPtY+3atUlhYWHywgsvJO+8807f49SpU6PVQp9Me/lzF8o3LGXaR0tLS3LppZcmixcvTg4ePJj85Cc/ScaPH5985zvfGa0W+mTaS11dXXLppZcm//zP/5wcPnw4+elPf5pcddVVyVe+8pXRaiFJkiQ5depUsm/fvmTfvn1JRCTr1q1L9u3bl/zud79LkiRJli1blsybN69v/4dfQ/6Nb3wj2b9/f7Jhw4ZBfQ35cMiV2ZUkuTO/cmV2JUnuzK9cmV1Jkjvzy+y68GZXkuTO/MqV2ZUkuTO/Rmt2CckAPoJ//Md/TK644oqksLAwmT17dvKv//qvfb/3hS98IVmwYEG//T/84Q+Tq6++OiksLEz+8i//MtmxY8cIVzywTPr45Cc/mUTEaY+6urqRL3wAmf6Z/EcXygu1JMm8j9deey2pqKhIioqKkiuvvDL57ne/m3zwwQcjXPXAMunl/fffT771rW8lV111VVJcXJyUl5cnDz74YPL//t//G/nC/4Nf/OIXA/69/7D2BQsWJF/4whdOOzNjxoyksLAwufLKK5N/+qd/GvG6zyRXZleS5M78ypXZlSS5M79yYXYlSW7NL7PrwptdSZI78ytXZleS5Mb8Gq3ZlZckWXT/HAAAAAAMA59JBgAAAEDqCckAAAAASD0hGQAAAACpJyQDAAAAIPWEZAAAAACknpAMAAAAgNQTkgEAAACQekIyAAAAAFJPSAYAAABA6gnJAAAAAEg9IRkAAAAAqSckAwAAACD1/j+yVPWCiijcSQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "import matplotlib.pyplot as plt\n",
        "# Constrain most sources of randomness\n",
        "# (some torch backwards functions within CLIP are non-determinstic)\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "render_res = 224\n",
        "learning_rate = 0.0001\n",
        "n_iter = 2500\n",
        "res = 224\n",
        "obj_path = 'data/dog.obj'\n",
        "#output_dir = './output/'\n",
        "clip_model_name = 'ViT-B/32'\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#Path(os.path.join(output_dir, 'renders')).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "objbase, extension = os.path.splitext(os.path.basename(obj_path))\n",
        "\n",
        "# list of possible colors\n",
        "rgb_to_color = {(204/255, 1., 0.): \"highlighter\", (180/255, 180/255, 180/255): \"gray\"}\n",
        "color_to_rgb = {\"highlighter\": [204/255, 1., 0.], \"gray\": [180/255, 180/255, 180/255]}\n",
        "full_colors = [[204/255, 1., 0.], [180/255, 180/255, 180/255]]\n",
        "colors = torch.tensor(full_colors).to(device)\n",
        "\n",
        "#------------ MESH TO POINT CLOUD INIT---------------\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "#here we retrieve first the point cloud from the mesh (only for test purpose)\n",
        "mesh_o3d = o3d.io.read_triangle_mesh(obj_path)\n",
        "mesh_o3d.compute_vertex_normals()\n",
        "pcd = mesh_o3d.sample_points_poisson_disk(2048)\n",
        "o3d.io.write_point_cloud(\"dog.pcd\", pcd)\n",
        "display.stop()\n",
        "#------------ MESH TO POINT CLOUD END---------------\n",
        "\n",
        "# Load the point cloud using Open3D\n",
        "pcd = o3d.io.read_point_cloud(\"dog.pcd\")\n",
        "\n",
        "# Extract vertices and colors\n",
        "points = torch.tensor(np.asarray(pcd.points), dtype=torch.float32, device = device)\n",
        "\n",
        "\n",
        "# Create a tensor of gray colors for each point\n",
        "gray_rgb = torch.tensor(color_to_rgb[\"gray\"], dtype=torch.float32, device=device)  # Gray RGB value\n",
        "gray_colors = gray_rgb.unsqueeze(0).repeat(points.shape[0], 1)  # Repeat gray for all points\n",
        "\n",
        "# Create a PyTorch3D Pointclouds object\n",
        "point_cloud = Pointclouds(points=[points], features=[gray_colors])\n",
        "\n",
        "# Define multiple camera views\n",
        "num_views = 4\n",
        "elevations = [10, 20, 30, 40]  # Example elevation angles\n",
        "azimuths = [0, 90, 180, 270]   # Example azimuth angles\n",
        "Rs, Ts = zip(*(look_at_view_transform(20, elev, azim) for elev, azim in zip(elevations, azimuths)))\n",
        "\n",
        "# Initialize rasterizer and renderer\n",
        "raster_settings = PointsRasterizationSettings(\n",
        "    image_size=224,\n",
        "    radius=0.003,\n",
        "    points_per_pixel=10\n",
        ")\n",
        "# Initialize variables\n",
        "background = torch.tensor((1., 1., 1.)).to(device)\n",
        "\n",
        "# CLIP and Augmentation Transforms\n",
        "clip_normalizer = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "\n",
        "clip_transform = transforms.Compose([\n",
        "        transforms.Resize((res, res)),\n",
        "        clip_normalizer\n",
        "])\n",
        "\n",
        "augment_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(res, scale=(1, 1)),\n",
        "        transforms.RandomPerspective(fill=1, p=0.8, distortion_scale=0.5),\n",
        "        clip_normalizer\n",
        "])\n",
        "\n",
        "# MLP Settings\n",
        "mlp = NeuralHighlighter().to(device)\n",
        "optim = torch.optim.Adam(mlp.parameters(), learning_rate)\n",
        "\n",
        "#introducing learning rate decay\n",
        "#with the prompt horse/saddle the loss plateaus\n",
        "#scheduler = StepLR(optim, step_size=300, gamma=0.1)\n",
        "\n",
        "#scheduler = MultiStepLR(optim, milestones=[300, 1800], gamma=0.1)  # Decay a epoch 300 e 1800\n",
        "\n",
        "name = 'dogPC_d_{}_augs_{}'.format(depth, n_augs)\n",
        "\n",
        "# --- Prompt ---\n",
        "# encode prompt with CLIP\n",
        "clip_model, preprocess = get_clip_model(clip_model_name)\n",
        "#prompts = ['A 3D render of a gray horse with highlighted hat',\n",
        "#           'A 3D render of a gray horse with highlighted shoes',\n",
        "#           'A 3D render of a gray horse with highlighted saddle']\n",
        "prompts = ['A 3D render of a point cloud of a gray dog with highlighted hat']\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "\n",
        "  output_dir = './output_{}_{}/'.format(name, i)\n",
        "  Path(os.path.join(output_dir, 'renders')).mkdir(parents=True, exist_ok=True)\n",
        "  log_dir = output_dir\n",
        "\n",
        "  #here we compute the text encoding only once\n",
        "  #if we put it inside the loss, we repeat n_iter times the same computation\n",
        "  with torch.no_grad():\n",
        "    text_input = clip.tokenize([prompt]).to(device)\n",
        "    encoded_text = clip_model.encode_text(text_input)\n",
        "    encoded_text = encoded_text / encoded_text.norm(dim=1, keepdim=True)\n",
        "\n",
        "  n_views = 5\n",
        "\n",
        "  losses = []\n",
        "\n",
        "\n",
        "  # Optimization loop\n",
        "  for i in tqdm(range(n_iter)):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    # predict highlight probabilities\n",
        "    pred_class = mlp(points)\n",
        "\n",
        "\n",
        "    print(pred_class)\n",
        "\n",
        "\n",
        "    #point cloud coloring\n",
        "    point_colors = assign_colors(pred_class, colors, device)\n",
        "\n",
        "    # color and render mesh\n",
        "    sampled_pcd = Pointclouds(points=[points], features=[point_colors])\n",
        "\n",
        "    # Render images from multiple views\n",
        "    rendered_images = []\n",
        "    for R, T in zip(Rs, Ts):\n",
        "        # Create a new camera for the current view\n",
        "        cameras = FoVOrthographicCameras(device=device, R=R, T=T, znear=0.01)\n",
        "\n",
        "        # Initialize the renderer with the new camera\n",
        "        renderer = PulsarPointsRenderer(\n",
        "            rasterizer=PointsRasterizer(cameras=cameras, raster_settings=raster_settings),\n",
        "            n_channels=3\n",
        "        ).to(device)\n",
        "\n",
        "        # Render the image for the current camera view\n",
        "        image = renderer(\n",
        "            sampled_pcd,\n",
        "            gamma=(1e-4,),\n",
        "            bg_col=background\n",
        "        )\n",
        "        # Visualize\n",
        "        #plt.imshow(image[0, ..., :3].detach().cpu().numpy())\n",
        "        #plt.show()\n",
        "        rendered_images.append(image.permute(0,3,1,2))  # Extract RGB channels\n",
        "    rendered_images = torch.stack(rendered_images).squeeze(1)\n",
        "    print(rendered_images.shape)\n",
        "    rendered_images = torch.tensor(rendered_images, dtype=torch.float32, device=device)\n",
        "\n",
        "    # Calculate CLIP Loss\n",
        "    loss = clip_loss(rendered_images, encoded_text, clip_transform, augment_transform, clip_model)\n",
        "\n",
        "    #loss = clip_loss_custom(encoded_text, rendered_images, clip_model, preprocess)\n",
        "    loss.backward(retain_graph=True)\n",
        "\n",
        "    optim.step()\n",
        "\n",
        "    #LR decay\n",
        "    #scheduler.step()\n",
        "\n",
        "    # update variables + record loss\n",
        "    with torch.no_grad():\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    # report results\n",
        "    if i % 100 == 0:\n",
        "        print(\"Last 100 CLIP score: {}\".format(np.mean(losses[-100:])))\n",
        "        save_renders(log_dir, i, rendered_images)\n",
        "        with open(os.path.join(log_dir, \"training_info.txt\"), \"a\") as f:\n",
        "            f.write(f\"For iteration {i}... Prompt: {prompt}, Last 100 avg CLIP score: {np.mean(losses[-100:])}, CLIP score {losses[-1]}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # # save point cloud results\n",
        "  io = IO()\n",
        "  io.save_pointcloud(sampled_pcd, f\"finalPcd.ply\")\n",
        "  # save point cloud results\n",
        "\n",
        "\n",
        "\n",
        "  # Save prompts\n",
        "  with open(os.path.join(output_dir, 'prompt.txt'), \"w\") as f:\n",
        "    f.write(prompt)\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"initial learning rate:\")\n",
        "    f.write(str(learning_rate))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"n_iter:\")\n",
        "    f.write(str(n_iter))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"n_augs:\")\n",
        "    f.write(str(n_augs))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"n_views:\")\n",
        "    f.write(str(n_views))\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"clip_model:\")\n",
        "    f.write(clip_model_name)\n",
        "    f.write(\"\\n\")\n",
        "    f.write(\"depth:\")\n",
        "    f.write(str(depth))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "juFBoZF-rNmV",
        "outputId": "01384eec-95c2-4eaa-a3c3-00d57220aa26"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2500 [00:00<?, ?it/s]<ipython-input-60-087cc8b7ce3b>:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  rendered_images = torch.tensor(rendered_images, dtype=torch.float32, device=device)\n",
            "  0%|          | 1/2500 [00:00<05:29,  7.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "Last 100 CLIP score: 0.6875\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 3/2500 [00:00<04:58,  8.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 5/2500 [00:00<04:34,  9.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 7/2500 [00:00<04:11,  9.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 11/2500 [00:01<04:01, 10.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 13/2500 [00:01<03:55, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 15/2500 [00:01<03:48, 10.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 17/2500 [00:01<04:01, 10.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 19/2500 [00:01<04:00, 10.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 21/2500 [00:02<04:19,  9.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 23/2500 [00:02<04:21,  9.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 25/2500 [00:02<04:54,  8.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 27/2500 [00:02<04:51,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 29/2500 [00:03<04:54,  8.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 31/2500 [00:03<04:58,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 32/2500 [00:03<04:55,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 34/2500 [00:03<05:02,  8.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 36/2500 [00:03<04:55,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 39/2500 [00:04<04:42,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 40/2500 [00:04<04:52,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 42/2500 [00:04<05:25,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 43/2500 [00:04<05:11,  7.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 45/2500 [00:05<05:05,  8.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 47/2500 [00:05<05:09,  7.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 49/2500 [00:05<05:14,  7.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 52/2500 [00:05<04:36,  8.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 53/2500 [00:06<04:39,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 57/2500 [00:06<03:47, 10.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 59/2500 [00:06<03:56, 10.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 61/2500 [00:06<03:56, 10.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 63/2500 [00:06<03:49, 10.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 67/2500 [00:07<03:48, 10.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 69/2500 [00:07<03:46, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 71/2500 [00:07<03:43, 10.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 73/2500 [00:07<03:57, 10.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 75/2500 [00:08<03:51, 10.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 79/2500 [00:08<03:51, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 81/2500 [00:08<03:47, 10.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 83/2500 [00:08<03:47, 10.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 85/2500 [00:09<03:38, 11.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 87/2500 [00:09<03:48, 10.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 89/2500 [00:09<03:45, 10.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 91/2500 [00:09<03:41, 10.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 95/2500 [00:09<03:54, 10.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 97/2500 [00:10<03:46, 10.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 99/2500 [00:10<03:36, 11.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 101/2500 [00:10<03:55, 10.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "Last 100 CLIP score: 0.693271484375\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 103/2500 [00:10<03:55, 10.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 105/2500 [00:10<03:52, 10.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 109/2500 [00:11<03:48, 10.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 111/2500 [00:11<03:47, 10.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 113/2500 [00:11<03:43, 10.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 115/2500 [00:11<03:42, 10.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 117/2500 [00:12<03:47, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 121/2500 [00:12<03:37, 10.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 123/2500 [00:12<03:45, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 125/2500 [00:12<03:44, 10.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 127/2500 [00:13<03:43, 10.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 131/2500 [00:13<03:43, 10.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 133/2500 [00:13<03:40, 10.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 135/2500 [00:13<03:38, 10.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 137/2500 [00:13<03:47, 10.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 139/2500 [00:14<03:44, 10.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 143/2500 [00:14<03:31, 11.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 145/2500 [00:14<03:45, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 147/2500 [00:14<03:43, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 149/2500 [00:15<03:46, 10.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 151/2500 [00:15<03:38, 10.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 155/2500 [00:15<03:45, 10.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 157/2500 [00:15<03:52, 10.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 159/2500 [00:16<04:12,  9.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 160/2500 [00:16<04:12,  9.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 162/2500 [00:16<04:09,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 164/2500 [00:16<04:24,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 166/2500 [00:16<04:30,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 168/2500 [00:17<04:45,  8.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 170/2500 [00:17<04:37,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 172/2500 [00:17<04:30,  8.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 174/2500 [00:17<04:32,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 176/2500 [00:18<04:41,  8.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 178/2500 [00:18<04:41,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 180/2500 [00:18<04:39,  8.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 182/2500 [00:18<04:49,  8.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 184/2500 [00:19<04:52,  7.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 186/2500 [00:19<04:44,  8.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 188/2500 [00:19<04:53,  7.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 190/2500 [00:19<05:01,  7.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 192/2500 [00:20<04:51,  7.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 193/2500 [00:20<04:35,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 197/2500 [00:20<03:56,  9.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 198/2500 [00:20<03:55,  9.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 202/2500 [00:21<03:47, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "Last 100 CLIP score: 0.6931982421875\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 204/2500 [00:21<03:51,  9.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 206/2500 [00:21<03:49, 10.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 208/2500 [00:21<03:44, 10.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 210/2500 [00:21<03:35, 10.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 212/2500 [00:22<03:42, 10.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 214/2500 [00:22<03:43, 10.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 216/2500 [00:22<03:33, 10.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 220/2500 [00:22<03:41, 10.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 222/2500 [00:23<03:41, 10.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 224/2500 [00:23<03:37, 10.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 226/2500 [00:23<03:29, 10.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 228/2500 [00:23<03:36, 10.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 232/2500 [00:24<03:29, 10.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 234/2500 [00:24<03:34, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 236/2500 [00:24<03:36, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 238/2500 [00:24<03:32, 10.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 242/2500 [00:24<03:34, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 244/2500 [00:25<03:31, 10.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 246/2500 [00:25<03:29, 10.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 248/2500 [00:25<03:35, 10.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 250/2500 [00:25<03:44, 10.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 252/2500 [00:25<03:47,  9.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 256/2500 [00:26<03:31, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 258/2500 [00:26<03:26, 10.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 260/2500 [00:26<03:37, 10.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 262/2500 [00:26<03:35, 10.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 264/2500 [00:27<03:26, 10.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 268/2500 [00:27<03:34, 10.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 270/2500 [00:27<03:27, 10.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 272/2500 [00:27<03:24, 10.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 274/2500 [00:28<03:31, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 276/2500 [00:28<03:29, 10.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 278/2500 [00:28<03:27, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 282/2500 [00:28<03:32, 10.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 284/2500 [00:28<03:29, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 286/2500 [00:29<03:21, 11.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 288/2500 [00:29<03:31, 10.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 290/2500 [00:29<03:32, 10.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 292/2500 [00:29<03:27, 10.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 296/2500 [00:30<03:26, 10.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 298/2500 [00:30<03:41,  9.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 300/2500 [00:30<03:55,  9.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 301/2500 [00:30<04:12,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "Last 100 CLIP score: 0.6894677734375\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 303/2500 [00:31<04:30,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 305/2500 [00:31<04:24,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 306/2500 [00:31<04:24,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 308/2500 [00:31<04:30,  8.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 310/2500 [00:31<04:18,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 312/2500 [00:32<04:24,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 314/2500 [00:32<04:19,  8.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 316/2500 [00:32<04:41,  7.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 318/2500 [00:32<04:54,  7.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 320/2500 [00:33<04:55,  7.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 321/2500 [00:33<04:44,  7.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 323/2500 [00:33<04:52,  7.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 325/2500 [00:33<04:46,  7.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 327/2500 [00:34<04:33,  7.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 328/2500 [00:34<04:29,  8.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 332/2500 [00:34<03:56,  9.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 334/2500 [00:34<03:51,  9.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 336/2500 [00:34<03:37,  9.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 338/2500 [00:35<03:30, 10.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 340/2500 [00:35<03:22, 10.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 342/2500 [00:35<03:29, 10.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 346/2500 [00:35<03:31, 10.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 348/2500 [00:36<03:33, 10.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 350/2500 [00:36<03:26, 10.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 352/2500 [00:36<03:31, 10.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 354/2500 [00:36<03:37,  9.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 356/2500 [00:36<03:32, 10.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 360/2500 [00:37<03:12, 11.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 362/2500 [00:37<03:23, 10.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 364/2500 [00:37<03:21, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 368/2500 [00:38<03:16, 10.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 370/2500 [00:38<03:23, 10.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 372/2500 [00:38<03:18, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 374/2500 [00:38<03:11, 11.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 378/2500 [00:38<03:25, 10.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 380/2500 [00:39<03:22, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 382/2500 [00:39<03:15, 10.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 386/2500 [00:39<03:21, 10.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 388/2500 [00:39<03:20, 10.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 390/2500 [00:40<03:20, 10.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 392/2500 [00:40<03:14, 10.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 394/2500 [00:40<03:22, 10.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 398/2500 [00:40<03:16, 10.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 400/2500 [00:41<03:26, 10.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 402/2500 [00:41<03:29, 10.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "Last 100 CLIP score: 0.693154296875\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 404/2500 [00:41<03:26, 10.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 406/2500 [00:41<03:19, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 408/2500 [00:41<03:18, 10.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 412/2500 [00:42<03:21, 10.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 414/2500 [00:42<03:15, 10.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 416/2500 [00:42<03:20, 10.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 418/2500 [00:42<03:20, 10.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 420/2500 [00:43<03:17, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 422/2500 [00:43<03:07, 11.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 426/2500 [00:43<03:13, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 428/2500 [00:43<03:12, 10.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 430/2500 [00:43<03:21, 10.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 432/2500 [00:44<03:18, 10.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 434/2500 [00:44<03:25, 10.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 437/2500 [00:44<03:46,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 439/2500 [00:44<03:56,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 441/2500 [00:45<03:56,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 443/2500 [00:45<04:17,  7.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 445/2500 [00:45<04:07,  8.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 447/2500 [00:45<04:05,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 449/2500 [00:46<04:16,  7.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 451/2500 [00:46<04:08,  8.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 452/2500 [00:46<04:28,  7.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 454/2500 [00:46<04:21,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 456/2500 [00:47<04:30,  7.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 458/2500 [00:47<04:33,  7.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 460/2500 [00:47<04:41,  7.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 462/2500 [00:47<04:44,  7.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▊        | 465/2500 [00:48<04:04,  8.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 467/2500 [00:48<03:44,  9.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 469/2500 [00:48<03:36,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 471/2500 [00:48<03:26,  9.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 475/2500 [00:49<03:18, 10.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 477/2500 [00:49<03:08, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 479/2500 [00:49<03:17, 10.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 481/2500 [00:49<03:16, 10.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 483/2500 [00:50<03:10, 10.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 487/2500 [00:50<03:12, 10.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 489/2500 [00:50<03:09, 10.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 491/2500 [00:50<03:06, 10.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 493/2500 [00:50<03:12, 10.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 495/2500 [00:51<03:10, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 497/2500 [00:51<03:06, 10.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 499/2500 [00:51<03:02, 10.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 501/2500 [00:51<03:17, 10.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: 0.68943359375\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 505/2500 [00:52<03:11, 10.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 507/2500 [00:52<03:08, 10.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 509/2500 [00:52<03:16, 10.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 511/2500 [00:52<03:16, 10.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 513/2500 [00:52<03:14, 10.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 517/2500 [00:53<03:05, 10.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 519/2500 [00:53<03:12, 10.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 521/2500 [00:53<03:08, 10.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 523/2500 [00:53<03:07, 10.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 525/2500 [00:54<03:16, 10.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 529/2500 [00:54<03:06, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 531/2500 [00:54<03:02, 10.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 533/2500 [00:54<03:10, 10.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 535/2500 [00:55<03:08, 10.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 537/2500 [00:55<03:04, 10.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 541/2500 [00:55<03:09, 10.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 543/2500 [00:55<03:05, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 545/2500 [00:55<03:06, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 547/2500 [00:56<03:06, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 549/2500 [00:56<03:12, 10.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 551/2500 [00:56<03:11, 10.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 555/2500 [00:56<03:13, 10.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 557/2500 [00:57<03:08, 10.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 559/2500 [00:57<03:02, 10.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 561/2500 [00:57<03:00, 10.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 565/2500 [00:57<03:02, 10.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 567/2500 [00:58<02:57, 10.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 569/2500 [00:58<03:15,  9.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 571/2500 [00:58<03:24,  9.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 573/2500 [00:58<03:37,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 575/2500 [00:59<03:52,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 577/2500 [00:59<03:39,  8.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 579/2500 [00:59<04:05,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 581/2500 [00:59<04:08,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 583/2500 [01:00<03:57,  8.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 585/2500 [01:00<03:52,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 587/2500 [01:00<04:07,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 589/2500 [01:00<03:58,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 591/2500 [01:01<03:58,  8.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 593/2500 [01:01<04:05,  7.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 595/2500 [01:01<04:06,  7.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 597/2500 [01:01<04:29,  7.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 599/2500 [01:02<04:20,  7.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 601/2500 [01:02<04:22,  7.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "Last 100 CLIP score: 0.691318359375\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 603/2500 [01:02<03:36,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 606/2500 [01:02<03:24,  9.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 608/2500 [01:03<03:10,  9.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 610/2500 [01:03<03:00, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 612/2500 [01:03<03:07, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 614/2500 [01:03<03:05, 10.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 618/2500 [01:04<02:57, 10.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 620/2500 [01:04<03:05, 10.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 622/2500 [01:04<03:02, 10.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 624/2500 [01:04<03:01, 10.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 626/2500 [01:04<03:03, 10.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 628/2500 [01:05<02:55, 10.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 632/2500 [01:05<02:56, 10.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 634/2500 [01:05<02:52, 10.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 636/2500 [01:05<03:02, 10.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 638/2500 [01:05<03:00, 10.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 640/2500 [01:06<02:57, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 642/2500 [01:06<02:51, 10.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 644/2500 [01:06<02:58, 10.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 648/2500 [01:06<03:02, 10.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 650/2500 [01:07<02:58, 10.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 652/2500 [01:07<02:55, 10.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 654/2500 [01:07<03:01, 10.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 656/2500 [01:07<03:04, 10.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▋       | 660/2500 [01:08<02:54, 10.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 662/2500 [01:08<02:48, 10.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 664/2500 [01:08<02:55, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 666/2500 [01:08<02:53, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 668/2500 [01:08<02:58, 10.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 672/2500 [01:09<02:58, 10.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 674/2500 [01:09<02:56, 10.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 676/2500 [01:09<02:51, 10.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 678/2500 [01:09<02:54, 10.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 680/2500 [01:10<02:54, 10.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 682/2500 [01:10<02:57, 10.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 686/2500 [01:10<02:49, 10.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 688/2500 [01:10<02:56, 10.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 690/2500 [01:10<02:55, 10.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 692/2500 [01:11<02:55, 10.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 694/2500 [01:11<02:52, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 698/2500 [01:11<02:51, 10.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 700/2500 [01:11<02:52, 10.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 702/2500 [01:12<02:56, 10.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "Last 100 CLIP score: 0.6905126953125\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 704/2500 [01:12<02:50, 10.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 706/2500 [01:12<03:07,  9.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 708/2500 [01:12<03:26,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 710/2500 [01:13<03:38,  8.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 712/2500 [01:13<03:04,  9.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([4, 3, 224, 224])\n",
            "tensor([[0.6405, 0.3595],\n",
            "        [0.4074, 0.5926],\n",
            "        [0.4766, 0.5234],\n",
            "        ...,\n",
            "        [0.5738, 0.4262],\n",
            "        [0.5316, 0.4684],\n",
            "        [0.5621, 0.4379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-087cc8b7ce3b>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# Render the image for the current camera view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         image = renderer(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0msampled_pcd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/points/pulsar/unified.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, point_clouds, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;31m# Go!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             images.append(\n\u001b[0;32m--> 545\u001b[0;31m                 self.renderer(\n\u001b[0m\u001b[1;32m    546\u001b[0m                     \u001b[0mvert_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvert_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                     \u001b[0mvert_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvert_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/points/pulsar/renderer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, vert_pos, vert_col, vert_rad, cam_params, gamma, max_depth, min_depth, bg_col, opacity, percent_allowed_difference, max_n_hits, mode, return_forward_info, first_R_then_T)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mfocal_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mprincipal_point_offsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_cam_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mcam_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/points/pulsar/renderer.py\u001b[0m in \u001b[0;36m_transform_cam_params\u001b[0;34m(cam_params, width, height, orthogonal, right_handed, first_R_then_T)\u001b[0m\n\u001b[1;32m    484\u001b[0m             ).repeat(batch_size, 1)[:, :, None],\n\u001b[1;32m    485\u001b[0m         )[:, :, 0]\n\u001b[0;32m--> 486\u001b[0;31m         sensor_dir_y = torch.matmul(\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0mrot_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             torch.tensor(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "kHJan6C91uqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate(dataloader, device):\n",
        "    # Constrain most sources of randomness\n",
        "    # (some torch backwards functions within CLIP are non-determinstic)\n",
        "    seed = 0\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    render_res = 224\n",
        "    res = 224\n",
        "    render = Renderer(dim=(render_res, render_res))\n",
        "    background = torch.tensor((1., 1., 1.)).to(device)\n",
        "    clip_model_name = 'ViT-B/32'\n",
        "\n",
        "\n",
        "    # CLIP and Augmentation Transforms\n",
        "    clip_normalizer = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "\n",
        "    clip_transform = transforms.Compose([\n",
        "            transforms.Resize((res, res)),\n",
        "            clip_normalizer\n",
        "    ])\n",
        "\n",
        "    augment_transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(res, scale=(1, 1)),\n",
        "            transforms.RandomPerspective(fill=1, p=0.8, distortion_scale=0.5),\n",
        "            clip_normalizer\n",
        "    ])\n",
        "\n",
        "\n",
        "    net = NeuralHighlighter().to(device)\n",
        "    net.eval()\n",
        "\n",
        "    output_dir = 'output_Pt3'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # list of possible colors\n",
        "    rgb_to_color = {(204/255, 1., 0.): \"highlighter\", (180/255, 180/255, 180/255): \"gray\"}\n",
        "    color_to_rgb = {\"highlighter\": [204/255, 1., 0.], \"gray\": [180/255, 180/255, 180/255]}\n",
        "    full_colors = [[204/255, 1., 0.], [180/255, 180/255, 180/255]]\n",
        "    colors = torch.tensor(full_colors).to(device)\n",
        "\n",
        "    clip_model, preprocess = get_clip_model(clip_model_name)\n",
        "\n",
        "    prompt = ['If you want to grap this mug, where will your palm position be?']\n",
        "\n",
        "\n",
        "    n_views = 5\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (points, affordance_labels) in enumerate(tqdm(dataloader)):\n",
        "            all_ious = []\n",
        "            #here we compute the text encoding only once\n",
        "            #if we put it inside the loss, we repeat n_iter times the same computation\n",
        "            with torch.no_grad():\n",
        "              text_input = clip.tokenize(prompt).to(device)\n",
        "              encoded_text = clip_model.encode_text(text_input)\n",
        "              encoded_text = encoded_text / encoded_text.norm(dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "            # -------------- POINT CLOUD TO MESH ---------------\n",
        "            points = points.squeeze(0).to(device)  # Ensure points are on the correct device\n",
        "            affordance_labels = affordance_labels.squeeze(0).to(device)  # Ensure labels are on the correct device\n",
        "\n",
        "            # Create Open3D point cloud and mesh\n",
        "            pcd = o3d.geometry.PointCloud()\n",
        "            pcd.points = o3d.utility.Vector3dVector(points.cpu().numpy())  # Transfer points to CPU for Open3D\n",
        "\n",
        "            # Estimate normals for the point cloud\n",
        "            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "\n",
        "            radii = [0.005, 0.01, 0.02, 0.04]\n",
        "            mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(pcd, o3d.utility.DoubleVector(radii))\n",
        "\n",
        "            # Export mesh to an obj file\n",
        "            output_mesh_file = \"mug.obj\"\n",
        "            o3d.io.write_triangle_mesh(output_mesh_file, mesh)\n",
        "\n",
        "            mesh = Mesh(output_mesh_file)\n",
        "            MeshNormalizer(mesh)  # Apply MeshNormalizer on CPU if necessary\n",
        "            #--------------- END POINT CLOUD TO MESH -------------\n",
        "\n",
        "\n",
        "            # Predict affordance\n",
        "            vertices = copy.deepcopy(mesh.vertices)\n",
        "            pred_class = net(vertices)  # Get predictions\n",
        "\n",
        "            # color and render predicted mesh\n",
        "            sampled_mesh = mesh\n",
        "            color_mesh(pred_class, sampled_mesh, colors)\n",
        "            rendered_images, elev, azim = render.render_views(sampled_mesh, num_views=n_views,\n",
        "                                                                    show=False,\n",
        "                                                                    center_azim=0,\n",
        "                                                                    center_elev=0,\n",
        "                                                                    std=1,\n",
        "                                                                    return_views=True,\n",
        "                                                                    lighting=True,\n",
        "                                                                    background=background)\n",
        "\n",
        "\n",
        "            # Compute IoU\n",
        "            IOU_thres = np.linspace(0,1,20)\n",
        "\n",
        "            pred_class = pred_class.cpu().numpy()\n",
        "\n",
        "            # Keep the first column (index 0) only, resulting in shape (2048, 1)\n",
        "            score = pred_class[:, 0].reshape(-1, 1)\n",
        "\n",
        "\n",
        "            target_score = affordance_labels.squeeze().cpu().numpy()\n",
        "\n",
        "            for thre in IOU_thres:\n",
        "                t_mask = (target_score > thre).astype(int)\n",
        "                p_mask = (score > thre).astype(int)\n",
        "                intersection = np.sum(t_mask & p_mask)\n",
        "                union = np.sum(p_mask | t_mask)\n",
        "\n",
        "                if union == 0:\n",
        "                    all_ious.append(np.nan)\n",
        "                else:\n",
        "                    all_ious.append(1. * intersection/union)\n",
        "\n",
        "            ious_array = np.array(all_ious)\n",
        "            mIOU = np.nanmean(all_ious)\n",
        "            print(f\"Mean Intersection over Union (mIOU): {mIOU:.4f}\")\n",
        "\n",
        "        return mIOU\n",
        "\n",
        "\n",
        "\n",
        "def combine_images(pred_image, gt_image):\n",
        "    \"\"\"Combine two images side by side.\"\"\"\n",
        "    pred_image_np = (pred_image.detach().cpu().numpy() * 255).astype(np.uint8).transpose(1, 2, 0)\n",
        "    gt_image_np = (gt_image.detach().cpu().numpy() * 255).astype(np.uint8).transpose(1, 2, 0)\n",
        "\n",
        "    pred_pil = Image.fromarray(pred_image_np)\n",
        "    gt_pil = Image.fromarray(gt_image_np)\n",
        "\n",
        "    combined_width = pred_pil.width + gt_pil.width\n",
        "    combined_height = max(pred_pil.height, gt_pil.height)\n",
        "    combined_image = Image.new('RGB', (combined_width, combined_height))\n",
        "\n",
        "    combined_image.paste(pred_pil, (0, 0))\n",
        "    combined_image.paste(gt_pil, (pred_pil.width, 0))\n",
        "\n",
        "    return combined_image\n",
        "\n",
        "\n",
        "print(\"Starting evaluation...\")\n",
        "mIOU = evaluate(val_loader, device)\n",
        "print(f\"Mean Intersection over Union (mIOU): {mIOU:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eOz-BZCLvC9S",
        "outputId": "abdf5d30-d7f6-42a0-8444-7c8cb405ec1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting evaluation...\n",
            "ModuleList(\n",
            "  (0): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (3): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (7): ReLU()\n",
            "  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (9): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (10): ReLU()\n",
            "  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (12): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (13): ReLU()\n",
            "  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (15): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (16): Softmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 1/13 [00:01<00:18,  1.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0112\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 2/13 [00:02<00:12,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0500\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 3/13 [00:03<00:09,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0000\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 4/13 [00:03<00:08,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.1890\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 5/13 [00:04<00:06,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0343\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 6/13 [00:05<00:05,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0490\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 7/13 [00:06<00:05,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0397\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 8/13 [00:07<00:04,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0828\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 9/13 [00:08<00:03,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0393\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 10/13 [00:09<00:02,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0468\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 11/13 [00:09<00:01,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0422\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 12/13 [00:10<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0177\n",
            "\u001b[1;33m[Open3D WARNING] Write OBJ can not include triangle normals.\u001b[0;m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 13/13 [00:11<00:00,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 13/13 [00:11<00:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Intersection over Union (mIOU): 0.0320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test\n"
      ],
      "metadata": {
        "id": "E6pnu1xq1q0H"
      }
    }
  ]
}